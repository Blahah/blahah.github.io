---
published: false
---

## Publication metrics measure privelege - and we're all gaming them

Evaluating scientists based on publication citations and impact factor have been coming under criticism [for at least 15 years](http://www.bmj.com/content/314/7079/497.1). [Nothing has changed](http://datapub.cdlib.org/2013/05/22/impact-factors/). As a young scientist collaborating on a variety of projects, I've got a bunch of papers in preparation with colleagues. This has made me accutely aware of the poisonous effect the metrics situation has on science.

My older or more experienced collaborators, almost without exception, are obsessed with publishing in high-impact journals. If it's not a Nature paper, it better be Science. Any 'lower' than that and we've essentially failed. REF assessments are coming up, and we need good papers or we've got no chance or progressing in our careers. We have to demonstrate **impact**. Whatever that is.

General interest journals like Nature and Science have some of the most overblown, sexed-up papers I've seen anywhere. By contrast, journals like PLOS tend to have interesting and thoughtful papers with claims that more closely match the results. Arxiv (not a peer reviewed journal) even more so. This is reflected in the relative retraction rates - [Impact Factor is correlated with retractions](http://iai.asm.org/content/79/10/3855.full).

Being in Cambridge, and being a white male, I'm always trying to be aware of my, and our, privelege. This situation is a grotesque example of it. People at institutions like this one publish in high-impact journals. They are constantly gaming the metrics system, whether they're conscious of it or not. That's just how metrics work - you measure people on something and they will optimise for it. They tend to cite other people at similar institutions, and be good at raising money from the networks of rich people and organisations associated with them. It's a bunch of rich white folks circle-citing one another.

Measuring scientists on citations and impact is just measuring their privelege.

Many other people recognise this, and are making an effort to break away from these crappy measures of science output to less power-concentrated ones. Movements like AltMetrics have risen, measuring 'impact' across social media and the web. Could this be different? Could it help us break away from concentrating privelege by praising people who have it?

No.

The whole damn system is about gaming. People who exercise influence and privelege in traditional avenues like journal publishing are more likely to score highly on traditional metrics, and people who exercise their influence and privelege in new media will be successful when measured by AltMetrics.

A recent [AltMetrics blog post about gaming AltMetrics ](http://www.altmetric.com/blog/gaming-altmetrics/) lists the ways people might try to get a higher AltMetrics score:


> 1. Alice has a new paper out. She tweets about it. HootSuite automatically posts all of her tweets to Facebook and Google+.
> 2. Alice has a new paper out. She writes about it on her lab’s blog and sends an email highlighting it to a colleague who reviews for Faculty of 1000.
> 3. Alice has a new paper out. She asks her colleagues to share it via social media if they think it’d be useful to others.
> 4. Alice has a new paper out. She asks those grad students of hers who blog to write about it.
> 5. Alice has a new paper out. She believes that it contains important information for diabetes patients and so pays for an in-stream advert on Twitter.
> 6. Alice has a new paper out. She believes that it contains important information for diabetes patients and so signs up to a ’100 retweets for $$$’ service.

They consider all of these acceptable except number 6. **What??** Why should financial privelege be treated differently from the social privelege of a researcher who asks a colleague to review for F1000? Or asks a friend with a load of twitter followers to retweet. I wouldn't do any of those things except the first one - but it's OK if people do, just don't reward them for it with Internet Points.

Privelege in general is the problem, and metrics of any kind that don't directly measure the quality of the ideas and execution, are making it worse. I'm not at all convinced that AltMetrics will help. The one arguably good thing that might come of this is that privelege diffuses a bit, and different people come to hold it.

I would love to hear ideas for how to avoid feeding into this metrics culture. At the moment I've got the choice of submitting basically every paper I'm on to Nature, or not being on any papers. At the moment my only plan is to ask for advice at the first Open ## 

Recent AltMetrics blog post about gaming AltMetrics http://www.altmetric.com/blog/gaming-altmetrics/

Points out that they consider it gaming when researchers pay for social media attention to their work.

Why should financial privelege be treated dfferently from the social privelege of a researcher who asks a colleage to review for F1000? Privelege in general is the problem, and publication metrics, including AltMetrics, are making it worse.

Quality of the science unrelated to perceived impact.